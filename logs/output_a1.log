I0106 23:35:07.453470 13685 caffe.cpp:343] Use GPU with device ID 0
==13685== NVPROF is profiling process 13685, command: ./caffe/build/tools/caffe time --model=proto_forceGradInput/a1.pt --iterations=10 --gpu 0 --logtostderr=1
I0106 23:35:08.344494 13685 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: proto_forceGradInput/a1.pt
I0106 23:35:08.344583 13685 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I0106 23:35:08.344611 13685 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: proto_forceGradInput/a1.pt
I0106 23:35:08.344626 13685 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0106 23:35:08.344635 13685 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0106 23:35:08.344758 13685 net.cpp:58] Initializing net from parameters: 
name: "ConvLayer_3x96x11x11"
force_backward: true
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 128
      dim: 3
      dim: 224
      dim: 224
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/11x11_s4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
I0106 23:35:08.344918 13685 layer_factory.hpp:77] Creating layer input
I0106 23:35:08.344988 13685 net.cpp:100] Creating Layer input
I0106 23:35:08.345005 13685 net.cpp:408] input -> data
I0106 23:35:08.368201 13685 net.cpp:150] Setting up input
I0106 23:35:08.368266 13685 net.cpp:157] Top shape: 128 3 224 224 (19267584)
I0106 23:35:08.368276 13685 net.cpp:165] Memory required for data: 77070336
I0106 23:35:08.368294 13685 layer_factory.hpp:77] Creating layer conv1
I0106 23:35:08.368330 13685 net.cpp:100] Creating Layer conv1
I0106 23:35:08.368357 13685 net.cpp:434] conv1 <- data
I0106 23:35:08.368386 13685 net.cpp:408] conv1 -> conv1/11x11_s4
I0106 23:35:08.370800 13685 net.cpp:150] Setting up conv1
I0106 23:35:08.370826 13685 net.cpp:157] Top shape: 128 64 55 55 (24780800)
I0106 23:35:08.370833 13685 net.cpp:165] Memory required for data: 176193536
I0106 23:35:08.370867 13685 net.cpp:228] conv1 does not need backward computation.
I0106 23:35:08.370875 13685 net.cpp:228] input does not need backward computation.
I0106 23:35:08.370882 13685 net.cpp:270] This network produces output conv1/11x11_s4
I0106 23:35:08.370898 13685 net.cpp:283] Network initialization done.
I0106 23:35:08.370949 13685 caffe.cpp:355] Performing Forward
I0106 23:35:29.473215 13685 caffe.cpp:360] Initial loss: 0
I0106 23:35:29.473292 13685 caffe.cpp:361] Performing Backward
I0106 23:36:46.343829 13685 caffe.cpp:369] *** Benchmark begins ***
I0106 23:36:46.343870 13685 caffe.cpp:370] Testing for 10 iterations.
I0106 23:38:20.204607 13685 caffe.cpp:398] Iteration: 1 forward-backward time: 93855.5 ms.
I0106 23:39:54.176539 13685 caffe.cpp:398] Iteration: 2 forward-backward time: 93966.7 ms.
I0106 23:41:27.651109 13685 caffe.cpp:398] Iteration: 3 forward-backward time: 93469.3 ms.
I0106 23:43:01.139454 13685 caffe.cpp:398] Iteration: 4 forward-backward time: 93483.1 ms.
I0106 23:44:33.969699 13685 caffe.cpp:398] Iteration: 5 forward-backward time: 92825 ms.
I0106 23:46:07.416231 13685 caffe.cpp:398] Iteration: 6 forward-backward time: 93441.3 ms.
I0106 23:47:39.668014 13685 caffe.cpp:398] Iteration: 7 forward-backward time: 92246.6 ms.
I0106 23:49:11.199620 13685 caffe.cpp:398] Iteration: 8 forward-backward time: 91526.5 ms.
I0106 23:50:42.567284 13685 caffe.cpp:398] Iteration: 9 forward-backward time: 91362.5 ms.
I0106 23:52:13.255388 13685 caffe.cpp:398] Iteration: 10 forward-backward time: 90683 ms.
I0106 23:52:13.255475 13685 caffe.cpp:401] Average time per layer: 
I0106 23:52:13.255491 13685 caffe.cpp:404]      input	forward: 0.0162432 ms.
I0106 23:52:13.255517 13685 caffe.cpp:407]      input	backward: 0.016304 ms.
I0106 23:52:13.255525 13685 caffe.cpp:404]      conv1	forward: 18745.9 ms.
I0106 23:52:13.255533 13685 caffe.cpp:407]      conv1	backward: 73939.8 ms.
I0106 23:52:13.255565 13685 caffe.cpp:412] Average Forward pass: 18746 ms.
I0106 23:52:13.255576 13685 caffe.cpp:414] Average Backward pass: 73939.9 ms.
I0106 23:52:13.255595 13685 caffe.cpp:416] Average Forward-Backward: 92686.1 ms.
I0106 23:52:13.255615 13685 caffe.cpp:418] Total Time: 926861 ms.
I0106 23:52:13.255625 13685 caffe.cpp:419] *** Benchmark ends ***
==13685== Profiling application: ./caffe/build/tools/caffe time --model=proto_forceGradInput/a1.pt --iterations=10 --gpu 0 --logtostderr=1
==13685== Profiling result:
==13685== Metric result:
"Device","Kernel","Invocations","Metric Name","Metric Description","Min","Max","Avg"
"Tesla K40c (0)","sgemm_sm35_ldg_nt_128x8x128x16x16",1408,"flop_count_sp","Floating Point Operations(Single Precision)",98729984,98729984,98729984
"Tesla K40c (0)","void scal_kernel<float, int=1, bool=0, int=6, int=5, int=5, int=3>(cublasTransposeParams<float>, float const *, float*, float const *)",1408,"flop_count_sp","Floating Point Operations(Single Precision)",23232,23232,23232
"Tesla K40c (0)","void gemmk1_kernel<float, int=256, int=5, bool=0, bool=0, bool=0, bool=0>(cublasGemmk1Params<float>, float const *, float const *, float*)",1408,"flop_count_sp","Floating Point Operations(Single Precision)",586850,586850,586850
"Tesla K40c (0)","void sgemm_largek_lds64<bool=1, bool=0, int=5, int=5, int=4, int=4, int=4, int=34>(float*, float const *, float const *, int, int, int, int, int, int, float const *, float const *, float, float, int, int, int*, int*)",1408,"flop_count_sp","Floating Point Operations(Single Precision)",149643264,149643264,149643264
"Tesla K40c (0)","sgemm_sm35_ldg_nt_64x16x128x8x32",1408,"flop_count_sp","Floating Point Operations(Single Precision)",6438912,6438912,6438912
"Tesla K40c (0)","void gemv2T_kernel_val<float, int=128, int=16, int=2, int=2, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",1408,"flop_count_sp","Floating Point Operations(Single Precision)",424776,424776,424776
"Tesla K40c (0)","sgemm_sm35_ldg_nn_64x16x64x16x16",1408,"flop_count_sp","Floating Point Operations(Single Precision)",145293312,145293312,145293312
"Tesla K40c (0)","void caffe::col2im_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, int, int, int, caffe::col2im_gpu_kernel<float>*)",1408,"flop_count_sp","Floating Point Operations(Single Precision)",1087212,1087212,1087212
"Tesla K40c (0)","void caffe::im2col_gpu_kernel<float>(int, float const *, int, int, int, int, int, int, int, int, int, int, int, int, caffe::im2col_gpu_kernel<float>*)",2816,"flop_count_sp","Floating Point Operations(Single Precision)",0,0,0
"Tesla K40c (0)","sgemm_sm35_ldg_nt_128x16x64x16x16",1408,"flop_count_sp","Floating Point Operations(Single Precision)",49364992,49364992,49364992
